# å°†csdnçš„åšå®¢çˆ¬å–åˆ°æœ¬åœ°å¹¶è¾“å‡ºä¸ºjekyllå¯è§£æçš„markdownæ ¼å¼ï¼ŒåŒæ—¶ä¿å­˜åšå®¢çš„å›¾ç‰‡åˆ°æœ¬åœ°

## å‰è¨€

åœ¨Github Pagesæ­å»ºä¸ªäººåšå®¢æ—¶åˆ©ç”¨ Jekyll ç”Ÿæˆç«™ç‚¹ï¼ŒJekyllæ˜¯ä¸€ä¸ªé™æ€ç«™ç‚¹ç”Ÿæˆå™¨ï¼Œå¯ä»¥æ ¹æ®Markdownæ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆé™æ€çš„htmlæ–‡ä»¶ã€‚ä¸”Github Pages æ”¯æŒæ‰˜ç®¡jekyllã€‚

å› æ­¤æˆ‘åªè¦åœ¨æœ¬åœ°ç¼–å†™ç¬¦åˆJekyllè§„èŒƒçš„Markdownæ–‡ä»¶ï¼Œä¸Šä¼ åˆ°Githubä¸Šï¼ŒGithub Pageså°±ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶æ‰˜ç®¡æ•´ä¸ªç½‘ç«™ã€‚

æˆ‘æƒ³æŠŠä¹‹å‰æˆ‘CSDNä¸Šå†™çš„åšå®¢å¤‡ä»½åˆ°æœ¬åœ°ï¼ŒåŒæ—¶åˆå¯ä»¥ä¸Šä¼ åˆ°Github Pagesæ­å»ºçš„ä¸ªäººåšå®¢ï¼Œé‚£ä¹ˆä¸€ä¸ªå¤§é—®é¢˜å°±æ¥äº†ï¼Œå¦‚ä½•å°†è‡ªå·±CSDNçš„åšå®¢æ‰¹é‡å¯¼å‡ºå¹¶è¾“å‡ºä¸ºjekyllå¯è§£æçš„markdownæ–‡ç« æ ¼å¼ï¼Œå¹¶ä¸”å°†åšå®¢ä¸­çš„å›¾ç‰‡ä¹Ÿä¿å­˜åˆ°æœ¬åœ°ã€‚

æ‰€ä»¥ç”¨pythonå†™äº†è¯¥è„šæœ¬ç”¨äºå®ç°æ‰€éœ€è¦çš„åŠŸèƒ½ã€‚



## ä»£ç å®ç°

çˆ¬å–csdnçš„åšå®¢å¹¶æ‰¹é‡è¾“å‡ºä¸ºjekyllå¯ä»¥ç›´æ¥è§£æçš„markdownæ ¼å¼ï¼Œå¯¹äºæ¯ä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬é‡ç‚¹å…³æ³¨ä»¥ä¸‹ä¿¡æ¯ï¼š

- æ ‡é¢˜ï¼ˆtitleï¼‰
- æ­£æ–‡
- å‘è¡¨æ—¶é—´ï¼ˆdateï¼‰
- æ‰€å±ç±»åˆ«ï¼ˆcategoriesï¼‰
- å¯¹åº”æ ‡ç­¾ï¼ˆtagsï¼‰

æ‹¬å·ä¸­çš„è‹±æ–‡å°±æ˜¯jekyllä¸‹åšå®¢æ‰€éœ€è¦çš„æ–‡ä»¶å¤´æ ¼å¼æ ‡å‡†ï¼Œæˆ‘ä»¬åªéœ€è¦å°†csdnä¸­æ¯ä¸€ç¯‡æ–‡ç« çš„ä¸Šè¿°å±æ€§çˆ¬å–ä¸‹æ¥å¹¶ä»¥ç‰¹å®šçš„æ ¼å¼å†™å…¥æ–‡ä»¶å³å¯ã€‚



### æ‰€éœ€è¦çš„åŒ…

```python
import os           
import sys
reload(sys)
sys.setdefaultencoding("utf-8")

# è‹¥è¦ä¿å­˜printå‡ºæ¥çš„æ—¥å¿—å†…å®¹åˆ™åŠ å…¥ä¸‹é¢ä¸¤è¡Œ
# mylog="mylog.log"
# sys.stdout = open(mylog,'w')

from lxml import etree
import requests
import html2text


from bs4 import BeautifulSoup
import codecs
import re

import imghdr   # å†…ç½®æ¨¡å—imghdrå¯ä»¥ç”¨æ¥åˆ¤æ–­å›¾ç‰‡çš„çœŸå®ç±»å‹ã€‚
import shutil   # ç”¨äºæ¸…ç©ºæŒ‡å®šæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶
```



### requestå­ç¨‹åº

é¦–å…ˆæˆ‘ä»¬åº”è¯¥é’ˆå¯¹csdnçš„åšå®¢ç³»ç»Ÿå†™ä¸€ä¸ªé€šç”¨çš„requestå‡½æ•°ï¼ˆæ–¹æ³•ï¼‰ï¼š

```python
# requestå­ç¨‹åº
def request_get(url):
    session = requests.Session()

    headers = {
        'User-Agent': 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.118 Safari/537.36'}
    response = requests.get(url, headers=headers, timeout=5)
    return response
```

è¿™é‡Œçš„headersé‡Œé¢çš„ä¿¡æ¯æ˜¯é€šè¿‡æŸ¥çœ‹é¡µé¢çš„å®¡æŸ¥å…ƒç´ ä¿¡æ¯æ‰¾åˆ°çš„ã€‚

### æ–‡ç« åœ°å€çˆ¬å–å­ç¨‹åº

è¯¥å­ç¨‹åºä¾æ­¤çˆ¬å–CSDNè´¦å·ä¸‹çš„æ¯ä¸€ç¯‡æ–‡ç« çš„åœ°å€ï¼Œåœ°å€ä¸­åŒ…å«idï¼Œç„¶åå†è°ƒç”¨çˆ¬å–å•ç¯‡åšå®¢æ–‡ç« çš„å­ç¨‹åºã€‚

usernameä¸ºcsdnçš„åœ°å€ä¸­çš„ç”¨æˆ·åã€‚æ³¨æ„çœ‹æ¯ä¸€è¡Œçš„æ³¨é‡Šã€‚

```python
# æ–‡ç« åœ°å€çˆ¬å–å­ç¨‹åº
def start_spider(username):
    # æŠŠä¸‹é¢è¿™ä¸ªbase_urlæ¢æˆä½ csdnçš„åœ°å€
    base_url = 'https://blog.csdn.net/' + username + '/'

    second_url = base_url + 'article/list/'
    # ä»ç¬¬ä¸€é¡µå¼€å§‹çˆ¬å–
    start_url = second_url + '1'

    number = 1      # è®°å½•å½“å‰æ˜¯ç¬¬å‡ ä¸ªarticle_list
    count = 0       # è®°å½•å½“å‰æ˜¯ç¬¬å‡ ç¯‡æ–‡ç« 

    # å¼€å§‹çˆ¬å–ç¬¬ä¸€ä¸ªarticle_listï¼Œè¿”å›ä¿¡æ¯åœ¨htmlä¸­
    html = request_get(start_url)

    # è¿™ä¸ªå¾ªç¯æ˜¯å¯¹åšå®¢çš„article_listé¡µé¢çš„å¾ªç¯
    while html.status_code == 200:          # 200è¯´æ˜request_getå®Œæˆï¼Œè¿™æ˜¯å› ä¸ºhttpåè®®é‡Œé¢å®šä¹‰çš„çŠ¶æ€ç 
        # è·å–ä¸‹ä¸€é¡µçš„ url
        selector = etree.HTML(html.text)

        # cur_article_list_page[0]å°±æ˜¯å½“å‰article_listé¡µé¢ä¸­çš„æ–‡ç« çš„list
        cur_article_list_page = selector.xpath('//*[@id="mainBox"]/main/div[2]')
        d = cur_article_list_page[0].xpath('//*[@id="mainBox"]/main/div[2]/div[2]/h4/a')
        l = cur_article_list_page[0].findall('data-articleid')

        # è¿™ä¸ªå¾ªç¯æ˜¯å¯¹ä½ æ¯ä¸€ä¸ªarticle_listä¸­çš„é‚£äº›æ–‡ç« çš„å¾ªç¯
        for elem in cur_article_list_page[0]:
            item_content = elem.attrib
            # é€šè¿‡å¯¹æ¯”æ‹¿åˆ°çš„æ•°æ®å’Œç½‘é¡µä¸­çš„æœ‰æ•ˆæ•°æ®å‘ç°è¿”å›æ¯ä¸€ä¸ªarticle_listä¸­çš„listéƒ½æœ‰ä¸€ä¸¤ä¸ªå¤šä½™å…ƒç´ ï¼Œæ¯ä¸ªå¤šä½™å…ƒç´ éƒ½æœ‰styleå±æ€§ï¼Œåˆ©ç”¨è¿™ä¸€ç‰¹ç‚¹è¿›è¡Œè¿‡æ»¤
            if item_content.has_key('style'):
                continue
            else:
                if item_content.has_key('data-articleid'):
                    # æ‹¿åˆ°æ–‡ç« å¯¹åº”çš„articleid
                    articleid = item_content['data-articleid']
                    # ç”¨äºæ‰“å°è¿›åº¦
                    count += 1
                    print("\n æ‰¾åˆ°ç¬¬" + str(count) + "ç¯‡åšå®¢ï¼Œæ­£åœ¨å¤„ç†...")
                    # çˆ¬å–å•ç¯‡æ–‡ç« 
                    CrawlingItemBlog(base_url, articleid)

        # è¿›è¡Œä¸‹ä¸€article_listçš„çˆ¬å–
        number += 1
        next_url = second_url + str(number)
        html = request_get(next_url)


```



### çˆ¬å–å•ç¯‡åšå®¢æ–‡ç« çš„å­ç¨‹åº

æŒ‰ç…§æ‹¿åˆ°çš„æ¯ä¸€ä¸ªæ–‡ç« åœ°å€ä¸­çš„idå¯¹å•ç¯‡æ–‡ç« è¿›è¡Œçˆ¬å–ï¼Œå¹¶è¾“å‡ºjekyllå¯è§£æçš„markdownæ–‡ç« æ ¼å¼ï¼ŒåŒæ—¶æŠ“å–åšå®¢ä¸­çš„å›¾ç‰‡ä¿å­˜åˆ°æœ¬åœ°ã€‚æ³¨æ„çœ‹æ¯ä¸€è¡Œçš„æ³¨é‡Šã€‚

jekyllä¸­markdownæ–‡ä»¶çš„å¤´æ ¼å¼å¦‚ä¸‹ã€‚

```markdown
    
    ---
        layout:     post
        title:      ""
        date:       2018-03-08 12:41:47
        author:     "Nick"
        header-img: "img/post-bg-2015.jpg"
        catalog: true
        tags:
            - ç”µè„‘æŠ€å·§
    ---
```
```python
# çˆ¬å–å•ç¯‡åšå®¢æ–‡ç« çš„å­ç¨‹åº
def CrawlingItemBlog(base_url, id):
    second_url = base_url + 'article/details/'
    url = second_url + id
    # å‘é€requestè¯·æ±‚å¹¶æ¥å—è¿”å›å€¼
    item_html = request_get(url)
    if item_html.status_code == 200:    # 200è¯´æ˜request_getå®Œæˆï¼Œè¿™æ˜¯å› ä¸ºhttpåè®®é‡Œé¢å®šä¹‰çš„çŠ¶æ€ç 
        '''
        éœ€è¦çš„ä¿¡æ¯ï¼š
        1ï¼šæ ‡é¢˜
        2ï¼šmarkdownå†…å®¹
        3ï¼šå‘è¡¨æ—¥æœŸ
        4ï¼šæ ‡ç­¾
        5ï¼šç±»åˆ«
        
        jekyllä¸­markdownæ–‡ä»¶çš„å¤´æ ¼å¼
        ---
            layout:     post
            title:      ""
            date:       2018-03-08 12:41:47
            author:     "Nick"
            header-img: "img/post-bg-2015.jpg"
            catalog: true
            tags:
                - ç”µè„‘æŠ€å·§
        ---
        '''

        # åˆ©ç”¨BeautifulSoupè§£æè¿”å›çš„html
        soup = BeautifulSoup(item_html.text, "lxml")
        # ç­›é€‰å‡ºåšå®¢æ­£æ–‡é‚£ä¸€éƒ¨åˆ†html
        c = soup.find(id="content_views")

        # æ ‡é¢˜
        title_article = soup.find(attrs={'class': 'title-article'})
        # è¿™é‡Œæ˜¯å°†æ ‡é¢˜ä½œä¸ºæœ€åå­˜å‚¨çš„æ–‡ä»¶å
        file_name = title_article.get_text()
        print(" è¯¥ç¯‡åšå®¢æ ‡é¢˜ä¸ºï¼š" + file_name)
        title_article = title_article.prettify()

        # è®¾ç½®jekyllæ ¼å¼åšå®¢å¼€å¤´çš„æ ¼å¼ï¼ˆtitleï¼‰
        jekyll_title = 'title:   ' + file_name + '\n'

        # æ–‡ç« çš„categories
        jekyll_categories = ''

        # æœ‰å¯èƒ½å‡ºç°è¿™ç¯‡æ–‡ç« æ²¡æœ‰categoriesçš„æƒ…å†µ
        try:
            jekyll_categories = soup.find(attrs={'class': 'tags-box space'}).find(attrs={'class': 'tag-link'}).get_text()
        except Exception:
            pass

        if jekyll_categories == '':
            pass
        else:
            # å»é™¤æ‹¿åˆ°çš„strä¸­çš„'\t'
            jekyll_categories = jekyll_categories.replace('\t', '')
            jekyll_categories = 'categories:\n' + '- ' + jekyll_categories + '\n'

        # è·å–æ–‡ç« å‘è¡¨æ—¶é—´
        time = soup.find(attrs={'class': 'time'}).get_text()
        s_time1 = time.split('å¹´')
        year = s_time1[0]
        s_time2 = s_time1[1].split('æœˆ')
        month = s_time2[0]
        s_time3 = s_time2[1].split('æ—¥')
        day = s_time3[0]
        minite = s_time3[1].strip()

        jekyll_date = 'date:   ' + year + '-' + month + '-' + day + ' ' + minite + '\n'

        jekyll_tags = ''

        # è·å–tagsæ ‡ç­¾
        tags = ''
        try:
            tags = soup.find(attrs={'class': 'tags-box artic-tag-box'}).get_text()
        except Exception:
            pass

        if tags == '':
            pass
        else:
            tags = tags.split('\n')
            tags = tags[2]
            tags = tags.replace('\t', ' ')
            tags = tags.split(' ')
            jekyll_tags = 'tags:\n'
            for tag in tags:
                if tag == '':
                    continue
                else:
                    jekyll_tags = jekyll_tags + '- ' + tag + '\n'

        # å°†htmlè½¬åŒ–ä¸ºmarkdown
        text_maker = html2text.HTML2Text()
        text_maker.bypass_tables = False
        text = text_maker.handle(c.prettify())

        # é€šè¿‡html2textè½¬æ¢å¾—åˆ°çš„markdwonæ–‡æœ¬ä¸­'img-'åé¢ä¼šæœ‰ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œå¯¼è‡´å›¾ç‰‡é“¾æ¥ä¸æ­£ç¡®
        # æ›´æ­£è½¬æ¢å¾—åˆ°çš„markdownæ–‡ä»¶ä¸­'img-\n'ä¸º'img-'ï¼Œå³åˆ é™¤'img-'åé¢çš„æ¢è¡Œç¬¦
        text_utf8 = text.encode('utf-8')
        text_utf8 = text_utf8.replace('-\n', '-')
        text_utf8 = text_utf8.replace('\n]', ']')
        text_utf8 = text_utf8.replace('\n/', '/')
        text_utf8_right = text_utf8.replace('https', 'http')
        # text_utf8_right = text_utf8.replace('?x-oss-\n', '?x-oss-')
        # print(text_utf8_right)
        text_utf8_right = text_utf8_right.replace('(//img-blog', '(http://img-blog')

        # æœ‰çš„æ–‡ç« åå­—ç‰¹æ®Šï¼Œä¼šæ–°å»ºæ–‡ä»¶å¤±è´¥
        try:
            # å†™å…¥æ–‡ä»¶
            md_file_name = './_posts/' + year + '-' + month + '-' + day + '-' + file_name + '.markdown'
            f = codecs.open(md_file_name, 'w', encoding='utf-8')
            jekyll_str = '---\n' + 'layout:  post\n' + jekyll_title + jekyll_date + 'author:  "å”ä¼ æ—"\nheader-img: "img/post-bg-2015.jpg"\ncatalog:   false\n' + jekyll_categories + jekyll_tags + '\n---\n'

            f.write(jekyll_str)
            f.write(text_utf8_right)
            f.close()
        except Exception:
            print(' å†™å…¥æ–‡ä»¶ ' + file_name + ' å‡ºé”™. ')


        # è‹¥ä¸çˆ¬å–å›¾ç‰‡ä¿å­˜ä¸‹æ¥ï¼Œåˆ™è¯¥CrawlingItemBlogå­ç¨‹åºä¸­ä»¥ä¸‹è¿™ä¸€å°æ®µåˆ°return Trueä¹‹å‰å¯ä»¥åˆ é™¤æˆ–è€…æ³¨é‡Šï¼Œå¯æé«˜çˆ¬å–åšå®¢çš„é€Ÿåº¦
        # çˆ¬å–æ¯ç¯‡åšå®¢çš„å›¾ç‰‡ä¿å­˜ä¸‹æ¥æ˜¯ä¸ºäº†ç»™åšå®¢åšå¤‡ä»½ï¼Œä¸‡ä¸€å“ªå¤©csdnæŒ‚äº†

        # è·å–å½“å‰è¯¥ç¯‡åšå®¢ä¸­æ‰€æœ‰å›¾ç‰‡çš„åœ°å€
        all_img = c.find_all('img')
        # print(all_img)
        k = 1 # å½“å‰è¯¥ç¯‡åšå®¢çš„å›¾ç‰‡åºå·ï¼Œä»1å¼€å§‹
        # éå†æ¯ä¸€å¼ å›¾ç‰‡å¹¶ä¿å­˜ä¸‹æ¥
        for img in all_img:     # èƒ½è¿›å…¥è¯¥å¾ªç¯åˆ™è¯´æ˜è¯¥ç¯‡åšå®¢ä¸­æœ‰å›¾ç‰‡
            # è‹¥è¯¥ç¯‡åšå®¢ä¸­æœ‰å›¾ç‰‡ï¼Œåˆ™ä»¥è¯¥ç¯‡åšå®¢çš„titleåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œ
            if k == 1:
                folder_path = './imgs/' + year + '-' + month + '-' + day + '-' + file_name
                mkdir(folder_path)
            # <class 'bs4.element.Tag'>è½¬string
            img_str = str(img)
            '''
            csdnåšå®¢é¡µé¢ä¸­ img åœ°å€æœ‰ä»¥ä¸‹6ç§æƒ…å†µï¼š
            1ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdn.net/20180403152931142?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RhbmdfQ2h1YW5saW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"/>
            2ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdnimg.cn/20190208181833408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RhbmdfQ2h1YW5saW4=,size_16,color_FFFFFF,t_70"/>
            3ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdnimg.cn/2019011319584747.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RhbmdfQ2h1YW5saW4=,size_16,color_FFFFFF,t_70"/>
            4ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdnimg.cn/20190214214731928.jpg"/>
            5ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdnimg.cn/20190113200938989.gif"/>
            6ã€<img alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°" src="https://img-blog.csdnimg.cn/20190108161409240.png"/>
            
            ä¸ºäº†å»é™¤csdnå›¾ç‰‡çš„æ°´å°ï¼Œå›¾ç‰‡åœ°å€?åé¢çš„ä¸œè¥¿ä¸è¦ï¼Œåˆ™è·å¾—çš„å›¾ç‰‡æ˜¯æ— æ°´å°çš„
            '''
            # re.findallä¸­çš„å‚æ•°éœ€è¦ä¸ºstringï¼Œæ­£åˆ™è¡¨è¾¾å¼æäº†å¥½ä¹…æ‰æå¯¹ï¼Œåœ¨notepad++é‡Œé¢æµ‹è¯•æ²¡é—®é¢˜çš„åœ¨pythonä¸‹æœ‰é—®é¢˜ï¼Œ
            img_url = re.findall(r"(?=img-blog).*?(?:\?|jpg|gif|png)", img_str)
            # img_url = re.findall(r"(?=img-blog).*?(?=\?)", img_str)     # è¯¥æ­£åˆ™è¡¨è¾¾å¼åªèƒ½æ‰¾åˆ°ç¬¬1ã€2ã€3ç§imgåœ°å€çš„æƒ…å†µ
            # print('img_str: ' + img_str)
            # print('img_url: ' + str(img_url))
            img_url_str = "".join(img_url)      # listè½¬string
            # print('img_url_str' + img_url_str)
            try:
                # ä¸‹è½½å›¾ç‰‡æš‚æ—¶å­˜ç›˜ä¸ºjpgæ ¼å¼
                ir = requests.get('https://' + img_url_str)
                img_name =  'temp.jpg'  # ä¸´æ—¶æ–‡ä»¶å
                if ir.status_code == 200:       # 200è¯´æ˜request_getå®Œæˆï¼Œè¿™æ˜¯å› ä¸ºhttpåè®®é‡Œé¢å®šä¹‰çš„çŠ¶æ€ç 
                    open(img_name , 'wb').write(ir.content)     # å­˜ç›˜
                # åˆ¤æ–­å›¾ç‰‡çœŸå®æ ¼å¼å¹¶é‡å‘½åæ”¹åç¼€ä¸ºçœŸå®æ ¼å¼
                img_real_name = folder_path + "/" + year + '-' + month + '-' + day + '-' + file_name + "_å›¾" + str(k) +  "." + imghdr.what(img_name)        # imghdr.what(img_name)ç”¨æ¥åˆ¤æ–­å›¾ç‰‡çœŸå®æ ¼å¼
                os.rename(img_name, img_real_name)      # os.renameå¯¹å›¾ç‰‡è¿›è¡Œé‡å‘½å
                k = k + 1       # å½“å‰è¯¥ç¯‡åšå®¢çš„å›¾ç‰‡åºå·é€’å¢1
            except Exception:
                print(" è·å–åšå®¢â€œ" + file_name + "â€çš„å›¾ç‰‡æ—¶å‡ºç°é”™è¯¯...\t\tæ­£åˆ™è¡¨è¾¾å¼ä¹‹å‰å›¾ç‰‡åœ°å€ï¼šhttp://" + img_str)
        return True
    else:
        return False


```

### æ–°å»ºå­æ–‡ä»¶å¤¹ç¨‹åº

è¯¥å­ç¨‹åºç”¨äºæ–°å»ºä¿å­˜markdownæ–‡ä»¶å’Œå›¾ç‰‡æ–‡ä»¶çš„æ–‡ä»¶å¤¹ã€‚

```python
# æ–°å»ºæ–‡ä»¶å¤¹å­ç¨‹åº
def mkdir(path):
    folder = os.path.exists(path)

    if not folder:  # åˆ¤æ–­æ˜¯å¦å­˜åœ¨æ–‡ä»¶å¤¹å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸ºæ–‡ä»¶å¤¹
        os.makedirs(path)  # makedirs åˆ›å»ºæ–‡ä»¶æ—¶å¦‚æœè·¯å¾„ä¸å­˜åœ¨ä¼šåˆ›å»ºè¿™ä¸ªè·¯å¾„
        return True
    else:
        return False
```

### ä¸»ç¨‹åº

```python
if __name__ == "__main__":
    username = 'Tang_Chuanlin'        # CSDN ä¸ªäººä¸»é¡µåœ°å€ä¸­çš„ç”¨æˆ·åï¼Œä¾‹å¦‚https://blog.csdn.net/Tang_Chuanlinä¸­çš„Tang_Chuanlin
    if os.path.exists('./imgs/'):      # åˆ¤æ–­å½“å‰è·¯å¾„ä¸‹æ˜¯å¦å­˜åœ¨"imgs"æ–‡ä»¶å¤¹
        shutil.rmtree('./imgs/')       # è‹¥å­˜åœ¨ï¼Œåˆ™åˆ é™¤è¯¥æ–‡ä»¶å¤¹ï¼Œç›®çš„æ˜¯åˆ é™¤ä¹‹å‰çˆ¬å–è·å¾—çš„å›¾ç‰‡
    mkdir('./imgs/')                   # "imgs"æ–°å»ºæ–‡ä»¶å¤¹
    if os.path.exists('./_posts/'):      # åˆ¤æ–­å½“å‰è·¯å¾„ä¸‹æ˜¯å¦å­˜åœ¨"_posts"æ–‡ä»¶å¤¹
        shutil.rmtree('./_posts/')       # è‹¥å­˜åœ¨ï¼Œåˆ™åˆ é™¤è¯¥æ–‡ä»¶å¤¹ï¼Œç›®çš„æ˜¯åˆ é™¤ä¹‹å‰çˆ¬å–è·å¾—çš„markdownæ–‡ä»¶
    mkdir('./_posts/')                   # "_posts"æ–°å»ºæ–‡ä»¶å¤¹
    print(" å¼€å§‹çˆ¬å– " + username + " çš„ CSDN åšå®¢... ")
    start_spider(username)              # å¼€å§‹çˆ¬å–
    print('successful!')                # å› ä¸ºæ˜¯æ­»å¾ªç¯ä¸€ç›´çˆ¬å–ï¼Œæ‰€ä»¥ä¸€èˆ¬éœ€è¦æ‰‹åŠ¨åœæ­¢
```



## é¡¹ç›®åœ°å€ï¼š

[CsdnBlogToJekyll](https://github.com/nicktcl/CsdnBlogToJekyll)ï¼ŒğŸ˜æ¬¢è¿ star ï¼Œæ¬¢è¿Fork! 




## ä½¿ç”¨æ–¹æ³•

- åœ¨pycharmä¸‹è¿è¡Œï¼Œç›´æ¥å°†å·¥ç¨‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå°†ï¼š

```python

if __name__ == "__main__":
    username = 'Tang_Chuanlin'        # CSDN ä¸ªäººä¸»é¡µåœ°å€ä¸­çš„ç”¨æˆ·åï¼Œä¾‹å¦‚https://blog.csdn.net/Tang_Chuanlinä¸­çš„Tang_Chuanlin
    if os.path.exists('./imgs/'):      # åˆ¤æ–­å½“å‰è·¯å¾„ä¸‹æ˜¯å¦å­˜åœ¨"imgs"æ–‡ä»¶å¤¹
        shutil.rmtree('./imgs/')       # è‹¥å­˜åœ¨ï¼Œåˆ™åˆ é™¤è¯¥æ–‡ä»¶å¤¹ï¼Œç›®çš„æ˜¯åˆ é™¤ä¹‹å‰çˆ¬å–è·å¾—çš„å›¾ç‰‡
    mkdir('./imgs/')                   # "imgs"æ–°å»ºæ–‡ä»¶å¤¹
    if os.path.exists('./_posts/'):      # åˆ¤æ–­å½“å‰è·¯å¾„ä¸‹æ˜¯å¦å­˜åœ¨"_posts"æ–‡ä»¶å¤¹
        shutil.rmtree('./_posts/')       # è‹¥å­˜åœ¨ï¼Œåˆ™åˆ é™¤è¯¥æ–‡ä»¶å¤¹ï¼Œç›®çš„æ˜¯åˆ é™¤ä¹‹å‰çˆ¬å–è·å¾—çš„markdownæ–‡ä»¶
    mkdir('./_posts/')                   # "_posts"æ–°å»ºæ–‡ä»¶å¤¹
    print(" å¼€å§‹çˆ¬å– " + username + " çš„ CSDN åšå®¢... ")
    start_spider(username)              # å¼€å§‹çˆ¬å–
    print('successful!')                # å› ä¸ºæ˜¯æ­»å¾ªç¯ä¸€ç›´çˆ¬å–ï¼Œæ‰€ä»¥ä¸€èˆ¬éœ€è¦æ‰‹åŠ¨åœæ­¢
    
```

ä¸­çš„usernameæ¢æˆè‡ªå·±csdnçš„ç”¨æˆ·åï¼Œç„¶ååœ¨pycharmä¸‹è¿è¡Œé¡¹ç›®å³å¯ï¼Œå› ä¸ºæ˜¯æ­»å¾ªç¯ä¸€ç›´çˆ¬å–ï¼Œæ‰€ä»¥ä¸€èˆ¬éœ€è¦æ‰‹åŠ¨åœæ­¢ã€‚

é¡¹ç›®è¿è¡Œå®Œæ¯•åmarkdownæ ¼å¼çš„æ–‡ç« ä¼šåœ¨â€œ_postsâ€æ–‡ä»¶å¤¹ä¸‹ï¼Œæ¯ç¯‡åšå®¢çš„å›¾ç‰‡ä¿å­˜åœ¨â€œimgsâ€æ–‡ä»¶å¤¹ä¸‹ã€‚



- åœ¨windows commandçª—å£ä¸‹ç›´æ¥è¿è¡Œæ—¶ï¼Œéœ€è¦å…ˆæ‰§è¡Œä»¥ä¸‹ä¸¤æ¡å‘½ä»¤ï¼Œå°†windows commandçª—å£çš„ç¼–ç æ”¹ä¸ºutf-8ã€‚

  ```cmd
  chcp 65001
  ```

  ```cmd
  set PYTHONIOENCODING=utf-8
  ```

  ç„¶åå†æ‰§è¡Œä»¥ä¸‹å‘½ä»¤è¿è¡Œpythonè„šæœ¬å³å¯ã€‚

  ```cmd
  python export_csdn_markdown.py
  ```

  

gifåŠ¨å›¾ä¸­æŠ“å–è¿‡ç¨‹ä¸­æœ‰ä¸€ç¯‡åšå®¢â€œè§£å†³You are using pip version 9.0.1, however version 9.0.3 is available. You should consider upgradingâ€ä¿å­˜å›¾ç‰‡æ—¶å‘é”™é”™è¯¯ï¼Œå¯èƒ½æ˜¯å› ä¸ºè¯¥ç¯‡åšå®¢æ ‡é¢˜è¿‡é•¿ï¼Œç„¶åæ–°å»ºå‡ºçš„æ–‡ä»¶å¤¹æ–‡ä»¶åè¿‡é•¿ï¼Œè¶…å‡ºwindowsæ–‡ä»¶å¤¹åé•¿åº¦çš„é™åˆ¶ï¼Œæ‰€ä»¥å‘ç”Ÿäº†å›¾ç‰‡ä¿å­˜æ—¶çš„é”™è¯¯ã€‚

## ç»“è¯­

è‡³æ­¤å°±å®Œæˆäº†å°†csdnçš„åšå®¢çˆ¬å–åˆ°æœ¬åœ°å¹¶è¾“å‡ºä¸ºjekyllå¯è§£æçš„markdownæ ¼å¼ï¼ŒåŒæ—¶ä¿å­˜ä¸‹äº†æ¯ä¸€ç¯‡åšå®¢çš„å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œç„¶åå°†å¯¼å‡ºçš„markdownæ ¼å¼çš„æ–‡ç« ï¼ˆé»˜è®¤åœ¨â€œ\_postsâ€ç›®å½•ä¸‹ï¼‰æ”¾åœ¨jekyllåšå®¢ç›®å½•çš„_postsæ–‡ä»¶å¤¹ä¸‹å³å¯ã€‚

## éœ€è¦æ³¨æ„çš„é—®é¢˜

####  1ã€jekyllä¸­postçš„markdownæ–‡ä»¶åæ ¼å¼å¦‚ä¸‹ï¼š

2019-02-13-Beautiful Soup 4.2.0 å®˜æ–¹ä¸­æ–‡æ–‡æ¡£.markdown

####  2ã€jekyllä¸­postçš„markdownæ–‡ä»¶å¤´æ ¼å¼å¦‚ä¸‹ï¼š

    ---    layout:		post
    title: 		é”™è¯¯ Unable to locate package python-pip
    date: 		2019-02-14 15:10:56
    author:		"å”ä¼ æ—"
    header-img: 	"img/post-bg-2015.jpg"
    catalog:	 true
    tags:
    - python
    ---    

tagsç­‰å…³é”®å­—åé¢çš„å†’å·å¿…é¡»ä¸ºè‹±æ–‡å†’å·ï¼Œä¸ºä¸­æ–‡å†’å·jekyllç¼–è¯‘ç”Ÿæˆçš„é¡µé¢ä¸­è¯¥ç¯‡æ–‡ç« ä¼šæ²¡æœ‰æ–‡ç« æ ‡é¢˜ã€ä½œè€…æ˜¾ç¤ºä¸å¯¹ã€æ—¥æœŸä¸å¯¹ç­‰é—®é¢˜ã€‚  
tagsä¸‹çš„æ ‡ç­¾ä¸è¦æ·»åŠ ç©ºæ ¼æˆ–tableã€‚  
titleä¸‹çš„å­—æ®µä¸èƒ½å¸¦æœ‰è‹±æ–‡æˆ–è€…ä¸­æ–‡å†’å·ï¼Œtitleå­—æ®µä¸­å¸¦æœ‰ä¸­æ–‡å†’å·jekyllç¼–è¯‘ç”Ÿæˆçš„é¡µé¢ä¸­è¯¥ç¯‡æ–‡ç« ä¼šæ²¡æœ‰æ–‡ç« æ ‡é¢˜ã€ä½œè€…æ˜¾ç¤ºä¸å¯¹ã€æ—¥æœŸä¸å¯¹ç­‰é—®é¢˜ã€‚  
titleä¸­å¯å¸¦æœ‰å•å¼•å·ã€‚

####  3ã€jekyllä¸­postçš„markdownæ–‡ä»¶éœ€è¦ä½¿ç”¨utf-8æ— BOMçš„ç¼–ç ï¼Œä¸èƒ½ä½¿ç”¨utf-8 BOMçš„ç¼–ç ã€‚

çˆ¬è™«ä¿å­˜çš„markdownæ–‡ä»¶é»˜è®¤ä¸ºutf-8æ— BOMçš„ç¼–ç ï¼Œä¸ç”¨è¿›è¡Œè½¬æ¢ã€‚csdnåœ¨çº¿markdownç¼–è¾‘å™¨å¯¼å‡ºçš„markdownæ–‡ä»¶é»˜è®¤ä¸ºutf-8 BOMçš„ç¼–ç ï¼Œéœ€è¦ç”¨notepad++è¿›è¡Œè½¬æ¢ä¸€ä¸‹ã€‚

####  4ã€çˆ¬è™«ä¿å­˜çš„markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥

æœ‰äº›å›¾ç‰‡é“¾æ¥ä¼šæ¢è¡Œï¼Œç¨‹åºä¸­å·²ç»å¯¹å¯èƒ½æ¢è¡Œçš„å›¾ç‰‡é“¾æ¥è¿›è¡Œäº†å¤„ç†ï¼Œè‹¥jekyllç¼–è¯‘ç”Ÿæˆçš„é¡µé¢ä¸­æ–‡ç« çš„å›¾ç‰‡ä¸æ­£å¸¸æ˜¾ç¤ºï¼Œåˆ™éœ€è¦äººå·¥æ£€æŸ¥å›¾ç‰‡é“¾æ¥æ˜¯å¦æ­£å¸¸ã€‚

####  5ã€å›¾ç‰‡é“¾æ¥éœ€è¦æ”¹ä¸ºhttpåè®®

çˆ¬è™«ä¿å­˜çš„markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥æœ‰äº›ä¸ºhttpåè®®çš„ï¼Œjekyllç”Ÿæˆçš„é¡µé¢ä¸­è¿™ç§å›¾ç‰‡æœ‰äº›ä¼šæ˜¾ç¤ºä¸æ­£å¸¸ï¼Œæ‰€ä»¥å›¾ç‰‡é“¾æ¥æœ€å¥½æ”¹ä¸ºhttpåè®®ã€‚ç¨‹åºä¸­å·²ç»å°†å›¾ç‰‡é“¾æ¥ä¸­çš„httpsæ›¿æ¢ä¸ºäº†httpã€‚


####  5ã€æ‰§è¡ŒæŠ¥é”™`LookupError: unknown encoding: cp65001`

cmdæ‰§è¡ŒæŠ¥é”™`LookupError: unknown encoding: cp65001`ï¼Œ æ‰§è¡Œ`set PYTHONIOENCODING=UTF-8`

